{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5300d3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import torch as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "import torchmetrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "from torch.optim.lr_scheduler import StepLR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a680947",
   "metadata": {},
   "source": [
    "### Для получения labels из названий папок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eacd84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDateset(Dataset):\n",
    "    def __init__(self, csv_data_path):\n",
    "        \n",
    "        self.df = pd.read_csv(csv_data_path)\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor()])\n",
    "                 # transforms.Normalize(mean = (0.5), std = (0.5))])\n",
    "         \n",
    "    def __len__(self):\n",
    "        return (len(self.df))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        image = cv2.imread(self.df.loc[i,'path'])        \n",
    "        label = self.df.loc[i,'lable']\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "    \n",
    "        return image, label # , scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f442982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = CustomDateset('./train.csv')\n",
    "val_data = CustomDateset('./val.csv')\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=10, shuffle=True, num_workers = 0)\n",
    "valloader = DataLoader(val_data, batch_size=10, shuffle=True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6efdc9-bde9-41a7-9664-ccbcaf85ba92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75200b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(trainloader, valloader, n_epochs, model = None):\n",
    "    #l2 regular parameter\n",
    "    l2_lambda = 0.001\n",
    "    # num classes\n",
    "    num_classes = 8\n",
    "    # learning rate\n",
    "    lr = 0.01\n",
    "\n",
    "    # loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # device\n",
    "    device = T.device('cuda' if T.cuda.is_available() else 'cpu')\n",
    "    if model is None:\n",
    "        model = models.resnet18(num_classes = 8).to(device)\n",
    "    # parallel device learning learning\n",
    "    # model= nn.DataParallel(model,device_ids = [0,1,2])\n",
    "\n",
    "    # metrics \n",
    "    Acc = torchmetrics.classification.MulticlassAccuracy(num_classes = 8, average='micro').to(device)\n",
    "    Precision = torchmetrics.classification.MulticlassPrecision(num_classes = 8, average=None).to(device)\n",
    "    Recall = torchmetrics.classification.MulticlassRecall(num_classes = 8, average=None).to(device)\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    # optimizer and lr step\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    for epoch in range(n_epochs):  # no. of epochs\n",
    "        # Train \n",
    "        running_train_loss = 0\n",
    "        running_train_precision = 0\n",
    "        running_train_recall = 0\n",
    "        running_train_acc = 0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for data in tqdm(trainloader, ncols=100):\n",
    "            # data pixels and labels to GPU if available\n",
    "            inputs = data[0].to(device, non_blocking=True)\n",
    "            labels = data[1].to(device, non_blocking=True)\n",
    "\n",
    "            # set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            outputs = T.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "            \n",
    "            # outputs,labels = outputs, labels.cpu().numpy()\n",
    "\n",
    "            precision = Precision(outputs, labels)\n",
    "            recall    = Recall(outputs, labels)\n",
    "            acc       = Acc(outputs, labels)\n",
    "            \n",
    "            # l2 regularization cumpute \n",
    "            l2_reg = torch.tensor(0.).to(device)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += l2_lambda * l2_reg\n",
    "            \n",
    "            # propagate the loss backward\n",
    "            loss.backward()\n",
    "            # update the gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_train_loss += loss.item()\n",
    "            running_train_precision += precision.cpu().numpy()\n",
    "            running_train_recall += recall.cpu().numpy()\n",
    "            running_train_acc += acc.item()\n",
    "                \n",
    "        # Validation\n",
    "        running_val_loss = 0\n",
    "        running_val_precision = 0\n",
    "        running_val_recall = 0\n",
    "        running_val_acc = 0\n",
    "            \n",
    "        model.eval()\n",
    "            \n",
    "        with T.no_grad():\n",
    "            for data in tqdm(valloader, ncols=100):\n",
    "                # data pixels and labels to GPU if available\n",
    "                inputs = data[0].to(device, non_blocking=True)\n",
    "                labels = data[1].to(device, non_blocking=True)\n",
    "    \n",
    "                # set the parameter gradients to zero\n",
    "                outputs = model.forward(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                outputs = T.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "                \n",
    "                # outputs,labels = outputs.cpu().numpy(), labels.cpu().numpy()\n",
    "\n",
    "                precision = Precision(outputs, labels)\n",
    "                recall    = Recall(outputs, labels)\n",
    "                acc       = Acc(outputs, labels)\n",
    "                \n",
    "                running_val_loss += loss.item()\n",
    "                running_val_precision += precision.cpu().numpy()\n",
    "                running_val_recall += recall.cpu().numpy()\n",
    "                running_val_acc += acc.item()\n",
    "                \n",
    "        scheduler.step()\n",
    "        \n",
    "        writer.add_scalar(\"Train/acc\", running_train_acc / len(trainloader), epoch + 1)\n",
    "        writer.add_scalar(\"Train/precision\", running_train_precision.mean() / len(trainloader), epoch + 1)\n",
    "        writer.add_scalar(\"Train/recall\", running_train_recall.mean() / len(trainloader), epoch + 1)\n",
    "        \n",
    "        writer.add_scalar(\"Train/loss\", running_train_loss / len(trainloader), epoch + 1)\n",
    "        \n",
    "        writer.add_scalar(\"Parameters/Learning Rate\", optimizer.param_groups[0]['lr'], epoch + 1)\n",
    "\n",
    "        writer.add_scalar(\"Val/acc\", running_val_acc/ len(valloader), epoch + 1)\n",
    "        writer.add_scalar(\"Val/precision\", running_val_precision.mean() / len(valloader), epoch + 1)\n",
    "        writer.add_scalar(\"Val/recall\", running_val_recall.mean() / len(valloader), epoch + 1)\n",
    "        writer.add_scalar(\"Val/loss\", running_val_loss / len(valloader), epoch + 1)\n",
    "    \n",
    "        print(f' Epoch       {epoch + 1}\\n', \n",
    "                f'loss:      {running_train_loss / len(trainloader)}\\n',\n",
    "                f'precision: {running_train_precision / len(trainloader)}\\n',\n",
    "                f'recall:    {running_train_recall / len(trainloader)}\\n',\n",
    "                f'acc:       {running_train_acc / len(trainloader)}\\n')\n",
    "        print('-------------------------------------------')\n",
    "        print(f'Validation  \\n', \n",
    "                f'loss:      {running_val_loss / len(valloader)}\\n',\n",
    "                f'precision: {running_val_precision / len(valloader)}\\n',\n",
    "                f'recall:    {running_val_recall / len(valloader)}\\n',\n",
    "                f'acc:       {running_val_acc / len(valloader)}\\n')\n",
    "        print('-------------------------------------------')\n",
    "        # save model\n",
    "        torch.save(model, './res18_lr' + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a39e348-b107-4efc-bb8a-d37f9b0d1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(trainloader, valloader, n_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6beefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet18(num_classes = 8)\n",
    "# torch.save(model, './net_learned_on_Medvedev_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b4b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf4b69-ada8-4adb-8856-0a46bca45eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
